# nyaturingtest/session.py
import asyncio
from collections.abc import Awaitable, Callable
from dataclasses import asdict, dataclass
from datetime import datetime, timedelta
from enum import Enum
import json
import random
import traceback
import uuid

import httpx
from nonebot import logger
import nonebot_plugin_localstore as store
from nonebot.utils import run_sync
from openai import AsyncOpenAI
from tortoise.transactions import in_transaction

from .client import LLMClient
from .config import plugin_config
from .emotion import EmotionState
from .vector_mem import VectorMemory
from .impression import Impression
from .mem import Memory, Message
from .presets import PRESETS
from .profile import PersonProfile
from .models import SessionModel, UserProfileModel, InteractionLogModel, GlobalMessageModel
from .utils import extract_and_parse_json, estimate_split_count, check_relevance
from .prompts import get_feedback_prompt, get_chat_prompt


@dataclass
class _SearchResult:
    mem_history: list[str]


class _ChattingState(Enum):
    ILDE = 0  # æ½œæ°´
    BUBBLE = 1  # å†’æ³¡
    ACTIVE = 2  # æ´»è·ƒ

    def __str__(self):
        match self:
            case _ChattingState.ILDE:
                return "æ½œæ°´çŠ¶æ€"
            case _ChattingState.BUBBLE:
                return "å†’æ³¡çŠ¶æ€"
            case _ChattingState.ACTIVE:
                return "å¯¹è¯çŠ¶æ€"


class Session:
    """
    ç¾¤èŠä¼šè¯ - æ‹ŸäººåŒ–ä¸²è¡Œç‰ˆ (çœŸå®æ„Ÿä¼˜å…ˆ)
    """

    def __init__(
            self,
            siliconflow_api_key: str,
            id: str = "global",
            name: str = "terminus",
            http_client: httpx.AsyncClient | None = None
    ):
        self.id = id
        if http_client:
            self._client_instance = http_client
        else:
            self._client_instance = httpx.AsyncClient(
                limits=httpx.Limits(max_keepalive_connections=5, max_connections=10),
                timeout=60.0
            )

        self.global_memory: Memory = Memory(
            llm_client=LLMClient(
                client=AsyncOpenAI(
                    api_key=plugin_config.nyaturingtest_siliconflow_api_key,
                    base_url="https://api.siliconflow.cn/v1",
                    http_client=self._client_instance
                )
            )
        )

        self.long_term_memory: VectorMemory = VectorMemory(
            api_key=plugin_config.nyaturingtest_siliconflow_api_key,
            persist_directory=f"{store.get_plugin_data_dir()}/vector_index_{id}",
        )

        self.__name = name
        self.__aliases: list[str] = []
        self.profiles: dict[str, PersonProfile] = {}
        self.global_emotion: EmotionState = EmotionState()
        self.chat_summary = ""
        self.__role = "ä¸€ä¸ªç”·æ€§äººç±»"

        # æ„æ„¿å€¼ç³»ç»Ÿ
        self.willingness: float = 0.0
        self.__chatting_state = _ChattingState.ILDE

        self.__search_result = None
        self._last_activity_time = datetime.now()
        self._last_speak_time = datetime.min
        self._active_count = 0
        self._loaded = False

        # ä¿æŒå¯¹åå°ä»»åŠ¡çš„å¼•ç”¨ï¼Œé˜²æ­¢è¢« GC
        self._background_tasks = set()

    def _sanitize(self, text: str) -> str:
        if not text: return ""
        try:
            return text.encode('utf-8', 'ignore').decode('utf-8')
        except:
            return ""

    def _escape_for_prompt(self, text: str) -> str:
        if not text: return ""
        return text.replace('"', '\\"').replace('\n', ' ')

    async def set_role(self, name: str, role: str):
        self.__role = role
        self.__name = name
        await self.save_session()

    def role(self) -> str:
        return f"{self.__name}ï¼ˆ{self.__role}ï¼‰"

    def name(self) -> str:
        return self.__name

    async def reset(self):
        self.__name = "terminus"
        self.__aliases = []
        self.__role = "ä¸€ä¸ªç”·æ€§äººç±»"
        await self.global_memory.clear()
        self.long_term_memory.clear()
        self.profiles = {}
        self.global_emotion = EmotionState()
        self.chat_summary = ""
        self.__chatting_state = _ChattingState.ILDE
        self.willingness = 0.0
        self._active_count = 0
        self._last_activity_time = datetime.now()
        self._last_speak_time = datetime.min
        await self.save_session()

    async def calm_down(self):
        self.global_emotion = EmotionState()
        self.profiles = {}
        self.__chatting_state = _ChattingState.ILDE
        self.willingness = 0.0
        self._active_count = 0
        self._last_activity_time = datetime.now()
        await self.save_session()

    async def save_session(self, force_index: bool = False):
        try:
            session_db, created = await SessionModel.update_or_create(
                id=self.id,
                defaults={
                    "name": self._sanitize(self.__name),
                    "role": self._sanitize(self.__role),
                    "aliases": self.__aliases,  # ä¿å­˜åˆ«å
                    "valence": self.global_emotion.valence,
                    "arousal": self.global_emotion.arousal,
                    "dominance": self.global_emotion.dominance,
                    "chat_summary": self._sanitize(self.chat_summary),
                    "last_speak_time": self._last_speak_time,
                    "chatting_state": self.__chatting_state.value
                }
            )

            # ä¿å­˜ç”¨æˆ·ç”»åƒ
            for user_id, profile in self.profiles.items():
                await UserProfileModel.update_or_create(
                    session=session_db,
                    user_id=str(user_id),
                    defaults={
                        "valence": profile.emotion.valence,
                        "arousal": profile.emotion.arousal,
                        "dominance": profile.emotion.dominance,
                    }
                )
            # ä¿å­˜çŸ­æ—¶æ¶ˆæ¯å†å²
            recent_msgs = self.global_memory.access().messages
            if recent_msgs:
                async with in_transaction():
                    await GlobalMessageModel.filter(session=session_db).delete()
                    bulk_msgs = []
                    for msg in recent_msgs:
                        bulk_msgs.append(GlobalMessageModel(
                            session=session_db,
                            user_name=self._sanitize(msg.user_name),
                            user_id=str(msg.user_id) if msg.user_id else "",
                            content=self._sanitize(msg.content),
                            time=msg.time,
                            msg_id=msg.id
                        ))
                    await GlobalMessageModel.bulk_create(bulk_msgs)

            # [æ–°å¢] è®°å¿†ç”Ÿå‘½å‘¨æœŸç®¡ç†ï¼š1% æ¦‚ç‡è§¦å‘æ¸…ç†ï¼Œæˆ–å¼ºåˆ¶ä¿å­˜æ—¶è§¦å‘
            if force_index or random.random() < 0.01:
                # æ¸…ç†è¶…è¿‡ 90 å¤©çš„æ—§è®°å¿†
                await run_sync(self.long_term_memory.cleanup)(days_retention=90)

            logger.debug(f"[Session {self.id}] æ•°æ®åº“ä¿å­˜æˆåŠŸ")
        except Exception as e:
            logger.warning(f"[Session {self.id}] æ•°æ®åº“ä¿å­˜è­¦å‘Š: {e}")

    async def load_session(self):
        if self._loaded: return

        session_db = await SessionModel.filter(id=self.id).first()
        if not session_db:
            logger.info(f"[Session {self.id}] åˆå§‹åŒ–æ–°ä¼šè¯")
            self._loaded = True
            return

        self.__name = session_db.name
        self.__role = session_db.role
        self.__aliases = session_db.aliases if session_db.aliases else []  # åŠ è½½åˆ«å
        self.chat_summary = session_db.chat_summary
        self.global_emotion.valence = session_db.valence
        self.global_emotion.arousal = session_db.arousal
        self.global_emotion.dominance = session_db.dominance
        if session_db.last_speak_time:
            self._last_speak_time = session_db.last_speak_time
        self.__chatting_state = _ChattingState(session_db.chatting_state)

        # [ä¼˜åŒ–] é‡å¯åç»™ä¸€ç‚¹ç‚¹åˆå§‹æ„æ„¿ï¼Œé˜²æ­¢Botå½»åº•è£…æ­»
        self.willingness = 0.1

        self.profiles = {}
        users_db = await UserProfileModel.filter(session=session_db).prefetch_related("interactions")
        for user_db in users_db:
            profile = PersonProfile(user_id=user_db.user_id)
            profile.emotion.valence = user_db.valence
            profile.emotion.arousal = user_db.arousal
            profile.emotion.dominance = user_db.dominance
            profile.last_update_time = user_db.last_update_time
            # åŠ è½½æœ€è¿‘äº¤äº’
            recent_logs = await user_db.interactions.all().order_by("-timestamp").limit(20)
            for log in reversed(recent_logs):
                imp = Impression(
                    timestamp=log.timestamp,
                    delta={"valence": log.delta_valence, "arousal": log.delta_arousal, "dominance": log.delta_dominance}
                )
                profile.interactions.append(imp)
            self.profiles[user_db.user_id] = profile

        msgs_db = await GlobalMessageModel.filter(session=session_db).order_by("-time").limit(50)
        history_msgs = []
        for msg_db in reversed(msgs_db):
            history_msgs.append(Message(
                time=msg_db.time,
                user_name=msg_db.user_name,
                content=msg_db.content,
                id=msg_db.msg_id,
                user_id=msg_db.user_id if msg_db.user_id else ""
            ))

        self.global_memory = Memory(
            llm_client=self.global_memory._Memory__llm_client,
            compressed_message=self.global_memory.access().compressed_history,
            messages=history_msgs
        )

        self._loaded = True
        logger.info(f"[Session {self.id}] åŠ è½½å®Œæˆ (åˆ«å: {self.__aliases})")

    def presets(self) -> list[str]:
        return [f"{filename}: {preset.name} {preset.role}" for filename, preset in PRESETS.items() if not preset.hidden]

    async def load_preset(self, filename: str) -> bool:
        if not filename.endswith(".json") and f"{filename}.json" in PRESETS.keys():
            filename = f"{filename}.json"
        if filename not in PRESETS.keys(): return False

        preset = PRESETS[filename]
        await self.set_role(preset.name, preset.role)
        self.__aliases = preset.aliases

        # [ä¿®å¤] åœ¨æ·»åŠ æ–°é¢„è®¾å‰ï¼Œåˆ é™¤æ—§çš„é¢„è®¾è®°å¿†ï¼Œé˜²æ­¢é‡å¤
        await run_sync(self.long_term_memory.delete_by_metadata)({"source": "preset"})

        to_add = (preset.knowledges + preset.relationships + preset.events + preset.bot_self)
        if to_add:
            metadatas = [{"source": "preset", "type": "rule"} for _ in to_add]
            await run_sync(self.long_term_memory.add_texts)(to_add, metadatas=metadatas)

        await self.save_session()
        return True

    def status(self) -> str:
        recent_messages = self.global_memory.access().messages
        recent_str = "\n".join([f"{m.user_name}: {m.content}" for m in recent_messages]) if recent_messages else "æ— "
        return f"""
åå­—ï¼š{self.__name}
è®¾å®šï¼š{self.__role}
æ„æ„¿å€¼ï¼š{self.willingness:.2f}
çŠ¶æ€: {self.__chatting_state}
æƒ…ç»ªï¼šV{self.global_emotion.valence:.2f} A{self.global_emotion.arousal:.2f} D{self.global_emotion.dominance:.2f}
æ‘˜è¦ï¼š{self.chat_summary}
æœ€è¿‘æ¶ˆæ¯ï¼š
{recent_str}
"""

    async def __search_stage(self, queries: list[str]):
        """
        ä¼˜åŒ–æ£€ç´¢é˜¶æ®µ
        """
        logger.debug("æ£€ç´¢é˜¶æ®µå¼€å§‹")

        # å¢åŠ å½“å‰è¯é¢˜æ‘˜è¦ä½œä¸ºæ£€ç´¢ä¸Šä¸‹æ–‡
        if self.chat_summary:
            queries.append(self.chat_summary)

        # å»é‡å¹¶è¿‡æ»¤
        queries = list(set([q for q in queries if q and q.strip()]))

        should_retrieve = self.willingness > 0.3  # åªæœ‰æ„æ„¿å°šå¯æ—¶æ‰æ£€ç´¢

        long_term_memory = []
        if should_retrieve and queries:
            logger.debug(f"è§¦å‘é•¿æœŸè®°å¿†æ£€ç´¢: {queries}")

            raw_results = await run_sync(self.long_term_memory.retrieve)(
                queries,
                k=20,
                where=None
            )

            if raw_results:
                formatted_results = []
                for item in raw_results:
                    content = item.get("content", "")
                    meta = item.get("metadata", {})
                    source = meta.get("source", "unknown")
                    # æ—¥æœŸæ ¼å¼åŒ–ä¼˜åŒ–
                    date_str = str(meta.get("date", ""))
                    prefix = "ã€è®¾å®šã€‘" if source == "preset" else f"ã€è®°å¿†/d:{date_str}ã€‘"
                    formatted_results.append(f"{prefix} {content}")

                # æŒ‰æ—¶é—´å€’åºæ’åˆ—ï¼ˆè™½ç„¶ RAG æ˜¯æŒ‰ç›¸å…³æ€§ï¼Œä½†è¿™é‡Œå¯ä»¥äºŒæ¬¡æ’åºï¼Œæˆ–è€…ç›´æ¥äº¤ç»™ LLMï¼‰
                long_term_memory = formatted_results
                logger.debug(f"æœç´¢ç»“æœï¼šå‘½ä¸­ {len(long_term_memory)} æ¡")

        self.__search_result = _SearchResult(mem_history=long_term_memory)

    async def __feedback_stage(self, messages_chunk: list[Message], llm_func: Callable):
        """
        åé¦ˆé˜¶æ®µï¼šåˆ†ææƒ…ç»ªã€æå–è®°å¿†ã€æ›´æ–°æ‘˜è¦
        """
        logger.debug(">> åé¦ˆé˜¶æ®µ (Feedback) å¼€å§‹")

        # 1. å‡†å¤‡ç”»åƒæ•°æ®
        reaction_users = list({msg.user_id if msg.user_id else msg.user_name for msg in messages_chunk})
        related_profiles = [self.profiles.get(uid, PersonProfile(user_id=uid)) for uid in reaction_users]
        for p in related_profiles:
            if p.user_id not in self.profiles: self.profiles[p.user_id] = p

        related_profiles_json = json.dumps(
            [{"user_name": p.user_id, "emotion_tends_to_user": asdict(p.emotion)} for p in related_profiles],
            ensure_ascii=False, indent=2
        )
        search_history = self.__search_result.mem_history if self.__search_result else []

        # [ä¿®æ”¹] æ ¼å¼åŒ–æ¶ˆæ¯æ—¶åŒ…å« UserIDï¼Œä¾› LLM è¯†åˆ«
        formatted_msgs = [f"[ID:{msg.user_id}] {msg.user_name}: '{self._escape_for_prompt(msg.content)}'" for msg in
                          messages_chunk]

        # 2. è°ƒç”¨ LLM
        prompt = get_feedback_prompt(
            self.__name, self.__role, self.willingness,
            self.__chatting_state.value,
            self.global_memory.access().compressed_history,
            self.global_memory.access().messages,
            formatted_msgs,
            asdict(self.global_emotion),
            related_profiles_json, search_history, self.chat_summary
        )

        response_dict = {}
        try:
            # [Debug] è®°å½• LLM åŸå§‹è¾“å‡º
            response = await llm_func(prompt, json_mode=True)
            logger.debug(f"[Feedback LLM Output]:\n{response}")

            parsed = extract_and_parse_json(response)
            if parsed: response_dict = parsed
        except Exception as e:
            logger.error(f"åé¦ˆé˜¶æ®µ LLM é”™è¯¯: {e}")

        # 3. æ›´æ–°æƒ…ç»ª
        new_emo = response_dict.get("new_emotion", {})
        self.global_emotion.valence = new_emo.get("valence", self.global_emotion.valence)
        self.global_emotion.arousal = new_emo.get("arousal", self.global_emotion.arousal)
        self.global_emotion.dominance = new_emo.get("dominance", self.global_emotion.dominance)

        # 4. æ›´æ–°ç”¨æˆ·å°è±¡ (Emotion Tends)
        emo_tends = response_dict.get("emotion_tends", [])
        if isinstance(emo_tends, list):
            for i, msg in enumerate(messages_chunk):
                if i >= len(emo_tends): break
                uid = msg.user_id if msg.user_id else msg.user_name
                raw_delta = emo_tends[i]

                delta = {}
                if isinstance(raw_delta, (int, float)):
                    delta = {
                        "valence": float(raw_delta),
                        "arousal": abs(float(raw_delta)) * 0.5,
                        "dominance": 0.0
                    }
                elif isinstance(raw_delta, dict):
                    delta = raw_delta

                if uid in self.profiles and delta:
                    self.profiles[uid].push_interaction(
                        Impression(timestamp=datetime.now().astimezone(), delta=delta)
                    )

        for p in self.profiles.values():
            p.update_emotion_tends()
            p.merge_old_interactions()

        # 5. æ›´æ–°æ‘˜è¦
        self.chat_summary = str(response_dict.get("summary", self.chat_summary))

        # 6. [ä¼˜åŒ–] è®°å¿†æå–è½¬ä¸ºå¼‚æ­¥åå°ä»»åŠ¡ (Fire-and-forget)
        analyze_result = response_dict.get("analyze_result", [])
        if isinstance(analyze_result, list) and analyze_result:
            # --- [æ–°å¢é€»è¾‘] è®¡ç®—å…œåº• User ID ---
            unique_user_ids = {
                str(msg.user_id) for msg in messages_chunk
                if msg.user_id and str(msg.user_id).strip()
            }
            # å¦‚æœå½“å‰å¯¹è¯ç‰‡æ®µåªå±äºä¸€ä¸ªç”¨æˆ·ï¼Œé‚£ä¹ˆæ‰€æœ‰æå–å‡ºçš„è®°å¿†é»˜è®¤éƒ½å½’ä»–
            fallback_uid = list(unique_user_ids)[0] if len(unique_user_ids) == 1 else ""

            task = asyncio.create_task(
                self.__save_long_term_memory(analyze_result, default_user_id=fallback_uid)
            )
            self._background_tasks.add(task)
            task.add_done_callback(self._background_tasks.discard)

        # 7. æ›´æ–°æ„æ„¿å€¼ (ç”± LLM æœ€ç»ˆå†³å®š)
        try:
            new_willing = float(response_dict.get("willing", self.willingness))
            self.willingness = max(0.0, min(1.0, new_willing))
        except:
            pass

        # 8. ç®€å•çš„çŠ¶æ€æµè½¬é€»è¾‘
        random_threshold = random.uniform(0.4, 0.7)
        if self.willingness > random_threshold:
            if self.__chatting_state == _ChattingState.ILDE:
                self.__chatting_state = _ChattingState.BUBBLE
        elif self.willingness < 0.2:
            self.__chatting_state = _ChattingState.ILDE

        logger.debug(f"<< åé¦ˆç»“æŸ: æ„æ„¿ {self.willingness:.2f}, çŠ¶æ€ {self.__chatting_state}")

    async def __save_long_term_memory(self, analyze_result: list, default_user_id: str = ""):
        """
        åå°ä»»åŠ¡ï¼šä¿å­˜é•¿æœŸè®°å¿†åˆ°å‘é‡æ•°æ®åº“
        """
        try:
            texts = []
            metadatas = []
            today = int(datetime.now().strftime("%Y%m%d"))

            for item in analyze_result:
                content = ""
                uid = ""

                # æƒ…å†µA: LLM è¿”å›äº†çº¯å­—ç¬¦ä¸² (å·æ‡’æ ¼å¼)
                if isinstance(item, str) and item.strip():
                    content = item
                    uid = default_user_id
                # æƒ…å†µB: LLM è¿”å›äº†å­—å…¸ (æ ‡å‡†æ ¼å¼)
                elif isinstance(item, dict):
                    content = item.get("content", "")
                    uid = str(item.get("related_user_id", ""))
                    # å¦‚æœ LLM æ¼å¡«äº† IDï¼Œå°è¯•ä½¿ç”¨å…œåº• ID
                    if not uid and default_user_id:
                        uid = default_user_id

                if content:
                    texts.append(content)
                    metadatas.append({
                        "source": "memory",
                        "type": "event",
                        "date": today,
                        "user_id": uid
                    })

            if texts:
                # è¿™æ˜¯ä¸€ä¸ªé˜»å¡IOæ“ä½œï¼Œæ”¾å…¥ run_sync
                await run_sync(self.long_term_memory.add_texts)(texts, metadatas=metadatas)
                logger.debug(f"[Async] æå–å¹¶ä¿å­˜é•¿æœŸè®°å¿† ({len(texts)}æ¡) [å…œåº•ID: {default_user_id}]")
        except Exception as e:
            logger.error(f"[Async] ä¿å­˜è®°å¿†å¤±è´¥: {e}")

    async def __chat_stage(self, messages_chunk: list[Message], llm_func: Callable) -> list[dict]:
        logger.debug(">> å¯¹è¯é˜¶æ®µ (Chat) å¼€å§‹")
        search_history = self.__search_result.mem_history if self.__search_result else []
        formatted_msgs = [f"[ID:{msg.id}] {msg.user_name}: '{self._escape_for_prompt(msg.content)}'" for msg in
                          messages_chunk]

        prompt = get_chat_prompt(
            self.__name, self.__role, self.__chatting_state.value,
            self.global_memory.access().compressed_history,
            self.global_memory.access().messages,
            formatted_msgs,
            asdict(self.global_emotion),
            "{}",
            search_history, self.chat_summary
        )

        try:
            # [Debug] è®°å½• LLM åŸå§‹è¾“å‡º
            response = await llm_func(prompt, json_mode=True)
            logger.debug(f"[Chat LLM Output]:\n{response}")

            response_data = extract_and_parse_json(response)

            # å…¼å®¹ List è¿”å›ç±»å‹ï¼Œè‡ªåŠ¨åŒ…è£…
            replies = []
            if isinstance(response_data, dict):
                replies = response_data.get("reply", [])
            elif isinstance(response_data, list):
                # å¦‚æœ LLM ç›´æ¥è¿”å›äº†åˆ—è¡¨ï¼Œæˆ‘ä»¬å‡è®¾è¿™å°±æ˜¯å›å¤åˆ—è¡¨
                replies = response_data
                logger.warning("LLM è¿”å›äº† List è€Œé Objectï¼Œå·²è‡ªåŠ¨å…¼å®¹")

            if not isinstance(replies, list):
                return []

            if replies:
                self.willingness = max(0.0, self.willingness - 0.4)
                self.__chatting_state = _ChattingState.ACTIVE

            return replies
        except Exception as e:
            logger.error(f"å¯¹è¯é˜¶æ®µå¼‚å¸¸: {e}")
            return []

    async def update(self, messages_chunk: list[Message], llm_func: Callable[[str, bool], Awaitable[str]],
                     publish: bool = True) -> list[dict] | None:

        # 1. æ›´æ–°çŸ­æ—¶è®°å¿† (Buffer)
        def enable_hippo():
            self.__update_hippo = True

        await self.global_memory.update(messages_chunk, after_compress=enable_hippo)
        asyncio.create_task(self.save_session())

        if not publish: return None

        # 2. æ„æ„¿å€¼è®¡ç®— (ç¡®å®šæ€§é€»è¾‘)
        # æ—¶é—´è¡°å‡
        now = datetime.now()
        seconds_passed = (now - self._last_activity_time).total_seconds()
        decay = (seconds_passed / 60.0) * 0.05  # æ¯åˆ†é’Ÿè¡°å‡ 0.05
        self.willingness = max(0.0, self.willingness - decay)
        self._last_activity_time = now

        # è§¦å‘å¢ç›Š
        is_relevant = check_relevance(self.__name, self.__aliases, messages_chunk)
        if is_relevant:
            self.willingness = max(self.willingness, 0.95)  # è¢«å«åå­—ï¼Œæ„æ„¿å€¼è®¾ä¸ºè¾ƒé«˜
            logger.info("æ£€æµ‹åˆ°å¼ºå…³è”ï¼Œæ„æ„¿å€¼æå‡")
        else:
            # å³ä½¿æ²¡å«æˆ‘ï¼Œå¦‚æœæœ‰æ–°æ¶ˆæ¯ï¼Œä¹Ÿç¨å¾®å¢åŠ ä¸€ç‚¹å¥½å¥‡å¿ƒ
            self.willingness = min(1.0, self.willingness + 0.05 * len(messages_chunk))

        # 3. èŠ‚æµåˆ¤æ–­ (Gatekeeper)
        if self.willingness < 0.3 and not is_relevant:
            logger.debug(f"æ„æ„¿å€¼è¿‡ä½ ({self.willingness:.2f}) ä¸”æ— å¼ºå…³è”ï¼Œè·³è¿‡å“åº”")
            return None

        # 4. æ£€ç´¢é˜¶æ®µ (æå–å…³é”®è¯)
        # æ··åˆâ€œæœ€è¿‘æ¶ˆæ¯â€å’Œâ€œå½“å‰è¯é¢˜æ‘˜è¦â€æ¥ç”Ÿæˆæ£€ç´¢è¯ï¼Œæé«˜å‘½ä¸­ç‡
        queries = [msg.content for msg in messages_chunk[-2:]]
        if self.chat_summary and len(self.chat_summary) > 5:
            queries.append(self.chat_summary)
        await self.__search_stage(queries)

        # 5. [æ‹ŸäººåŒ–] ä¸²è¡Œæ‰§è¡Œ (å…ˆæ€è€ƒ/åé¦ˆï¼Œå†å†³å®šæ˜¯å¦è¯´è¯)
        # è¿™ç§æ¨¡å¼å»¶è¿Ÿè¾ƒé«˜ï¼Œä½†æƒ…ç»ªååº”æœ€çœŸå®ï¼Œä¸ä¼šå‡ºç°"è¢«éª‚äº†è¿˜ç¬‘å˜»å˜»"çš„æƒ…å†µ
        logger.debug("ğŸ¢ å¯ç”¨æ‹ŸäººåŒ–ä¸²è¡Œæ¨¡å¼: Feedback -> Check -> Chat")

        # 5.1 åé¦ˆä¸æ€è€ƒ (LLM æ›´æ–°æƒ…ç»ªã€æå–è®°å¿†ã€æœ€ç»ˆå†³å®šæ„æ„¿)
        # è¿™ä¸€æ­¥ä¼šæ›´æ–° self.global_emotion å’Œ self.willingness
        await self.__feedback_stage(messages_chunk, llm_func)

        # 5.2 å†æ¬¡æ£€æŸ¥æ„æ„¿ (Feedback é˜¶æ®µå¯èƒ½ä¼šæ ¹æ®æ–°æ¶ˆæ¯è°ƒæ•´æ„æ„¿)
        # å¦‚æœ Feedback åæ„æ„¿é™ä½(æ¯”å¦‚è§‰å¾—æ— èŠ)ï¼Œåˆ™åœæ­¢å›å¤
        if self.willingness < 0.4:
            return None

        # 5.3 å¯¹è¯æ‰§è¡Œ
        # æ­¤æ—¶ Chat é˜¶æ®µä½¿ç”¨çš„æ˜¯ Feedback æ›´æ–°åçš„æœ€æ–°æƒ…ç»ª
        reply_messages = await self.__chat_stage(messages_chunk, llm_func)

        if reply_messages:
            self._last_speak_time = datetime.now()
            asyncio.create_task(self.save_session())

        return reply_messages
